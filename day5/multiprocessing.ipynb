{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing\n",
    "\n",
    "## 1. process v.s. thread\n",
    "- [\"프로세스와 쓰레드의 차이\" 출처](https://gmlwjd9405.github.io/2018/09/14/process-vs-thread.html)\n",
    "\n",
    "### 프로세스(process)\n",
    "- 정의\n",
    "    - 컴퓨터에서 연속적으로 실행되고 있는 컴퓨터 프로그램\n",
    "    - 메모리에 올라와 실행되고 있는 프로그램의 인스턴스(독립적인 개체)\n",
    "    - 운영체제로부터 시스템 자원을 할당받는 작업의 단위\n",
    "    - 즉, 동적인 개념으로는 실행된 프로그램을 의미\n",
    "- 특징\n",
    "    - 프로세스는 각각 독립된 메모리 영역(Code, Data, Stack, Heap의 구조)을 할당받는다.\n",
    "    - 기본적으로 프로세스당 최소 1개의 스레드(메인 스레드)를 가지고 있다.\n",
    "    - 각 프로세스는 별도의 주소 공간에서 실행되며, 한 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수 없음\n",
    "    - 한 프로세스가 다른 프로세스의 자원에 접근하려면 프로세스 간의 통신(IPC, inter-process communication)을 사용해야 함\n",
    "        - Ex. 파이프, 파일, 소켓 등을 이용한 통신 방법 이용\n",
    "<img src=\"https://gmlwjd9405.github.io/images/os-process-and-thread/process.png\" width=\"400\">\n",
    "    \n",
    "### 쓰레드(thread)\n",
    "- 정의\n",
    "    - 프로세스 내에서 실행되는 여러 흐름의 단위\n",
    "    - 프로세스의 특정한 수행 경로\n",
    "    - 프로세스가 할당받은 자원을 이용하는 실행의 단위\n",
    "- 특징\n",
    "    - 스레드는 프로세스 내에서 각각 Stack만 따로 할당받고 Code, Data, Heap 영역은 공유\n",
    "    - 스레드는 한 프로세스 내에서 동작되는 여러 실행의 흐름으로, 프로세스 내의 주소 공간이나 자원들(힙 공간 등)을 같은 프로세스 내에 스레드끼리 공유하면서 실행\n",
    "    - 같은 프로세스 안에 있는 여러 스레드들은 같은 힙 공간을 공유\n",
    "        - 반면에 프로세스는 다른 프로세스의 메모리에 직접 접근할 수 없음\n",
    "    - 각각의 스레드는 별도의 레지스터와 스택을 갖고 있지만, 힙 메모리는 서로 읽고 쓸 수 있음\n",
    "    - 한 스레드가 프로세스 자원을 변경하면, 다른 이웃 스레드(sibling thread)도 그 변경 결과를 즉시 볼 수 있음\n",
    "<img src=\"https://gmlwjd9405.github.io/images/os-process-and-thread/thread.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. multi-processing v.s. multi-threading\n",
    "\n",
    "### 멀티 프로세싱(multi-processing)\n",
    "- 하나의 응용프로그램을 여러 개의 프로세스로 구성하여 각 프로세스가 하나의 작업(태스크)을 처리하도록 하는 것\n",
    "- 장점: 여러 개의 자식 프로세스 중 하나에 문제가 발생하면 그 자식 프로세스만 죽는 것 이상으로 다른 영향이 확산되지 않음\n",
    "- 단점\n",
    "    - Context Switching에서의 오버헤드\n",
    "        - Context Switching 과정에서 캐쉬 메모리 초기화 등 무거운 작업이 진행되고 많은 시간이 소모되는 등의 오버헤드가 발생하게 됨\n",
    "        - 프로세스는 각각의 독립된 메모리 영역을 할당받았기 때문에 프로세스 사이에서 공유하는 메모리가 없어, Context Switching가 발생하면 캐쉬에 있는 모든 데이터를 모두 리셋하고 다시 캐쉬 정보를 불러와야 함\n",
    "    - 프로세스 사이의 어렵고 복잡한 통신 기법(IPC)\n",
    "        - 프로세스는 각각의 독립된 메모리 영역을 할당받았기 때문에 하나의 프로그램에 속하는 프로세스들 사이의 변수를 공유할 수 없음\n",
    "    <img src=\"https://magi82.github.io/images/2017-2-6-process-thread/02.png\" width=\"500\">\n",
    "        \n",
    "### 멀티 쓰레딩(multi-threading)\n",
    "- 하나의 응용프로그램을 여러 개의 스레드로 구성하고 각 스레드로 하여금 하나의 작업을 처리하도록 하는 것\n",
    "    - 윈도우, 리눅스 등 많은 운영체제들이 멀티 프로세싱을 지원하고 있지만 멀티 스레딩을 기본으로 하고 있음\n",
    "    - 웹 서버는 대표적인 멀티 스레드 응용 프로그램\n",
    "- 장점\n",
    "    - 시스템 자원 소모 감소 (자원의 효율성 증대): 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어들어 자원을 효율적으로 관리할 수 있음\n",
    "    - 시스템 처리량 증가 (처리 비용 감소)\n",
    "        - 스레드 간 데이터를 주고 받는 것이 간단해지고 시스템 자원 소모가 줄어들게 됨\n",
    "        - 스레드 사이의 작업량이 작아 Context Switching이 빠름\n",
    "    - 간단한 통신 방법으로 인한 프로그램 응답 시간 단축\n",
    "        - 스레드는 프로세스 내의 Stack 영역을 제외한 모든 메모리를 공유하기 때문에 통신의 부담이 적음\n",
    "- 단점\n",
    "    - 주의 깊은 설계가 필요\n",
    "    - 디버깅이 까다로움\n",
    "    - 단일 프로세스 시스템의 경우 효과를 기대하기 어려움\n",
    "    - 다른 프로세스에서 스레드를 제어할 수 없음 (즉, 프로세스 밖에서 스레드 각각을 제어할 수 없음)\n",
    "        - interrupt/kill 할 수 없음\n",
    "    - 멀티 스레드의 경우 자원 공유의 문제가 발생 (동기화 문제)\n",
    "    - 하나의 스레드에 문제가 발생하면 전체 프로세스가 영향을 받음\n",
    "    <img src=\"https://gmlwjd9405.github.io/images/os-process-and-thread/multi-thread.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. python에서의 multi-processing v.s. multi-threading\n",
    "\n",
    "- [\"python 강의 정리 / 멀티쓰레드, 멀티프로세스, gevent\" 출처](http://blog.naver.com/PostView.nhn?blogId=sung487&logNo=221012867298\n",
    "\n",
    "\n",
    "- 파이썬은 **멀티스레딩을 지원하기 위하여 GIL(Global Interpreter Lock), 즉 전역 인터프리터 락을 도입**하여 사용\n",
    "    - 따라서 **python 스레드 10개를 만들어도 실제 Pthread/윈도우 스레드가 10개가 만들어지긴 하는데, GIL때문에 동시에 하나밖에 안돌아가는 기이한 구조**\n",
    "- 이것은 구현이 매우 쉬워지고 빠른 개발을 할 수 있다는 장점, BUT 멀티 코어 CPU가 보편화된 2006년 이후에는 멀티 코어를 제대로 활용하지 못하는 구조적인 문제 때문에 성능에서 밀린다는 평가를 받음\n",
    "- 만일 특정 프로그램에 순진하게 CPU 코어를 2개 이상 동원하려고 할 경우, 뮤텍스(MutEx), 즉 한 스레드에 여러 개의 CPU가 연산을 행하여 내부 정보를 오염 시키는 것을 방지하는 역할을 맡는 GIL이 병목 현상을 일으켜 코어 하나를 쓸 때보다 오히려 성능이 크게 저하\n",
    "    - 구글 내부에서 이미 가루가 되도록 까인 부분이라고 함\n",
    "- **이런 문제점 때문에 파이썬에서 병렬 처리가 필요할 때는 다중 스레드가 아닌 다중 프로세스로 GIL을 우회**하는 방식을 사용\n",
    "    - 2008년 이후에 multiprocessing이라는 모듈을 제공하는데 이 모듈은 자식 프로세스를 만드는 방향으로 다중 코어 사용 시 성능의 향상을 꾀하고 있음\n",
    "\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/99231D465A7BD9C81C\" width=\"400\">\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/9923D8495A7BD9D406\" width=\"600\">\n",
    "\n",
    "\n",
    "### 그래서 뭘 써야 하는가?\n",
    "\n",
    "- CPU 부하가 큰 작업을 돌리는 것이 아니면 GIL을 체감하기는 생각보다 쉽지 않음\n",
    "- 다중 스레딩으로 CPU의 여러 코어를 최대한 이용하고 싶은 경우에는 GIL가 굉장히 아쉬운 이슈지만, CPU를 별로 쓰지 않거나 I/O가 주가 되는 작업은 유의미한 성능 차이가 없음\n",
    "    - 게다가 어설프게 코어 몇개 이용해서 계산하는 것보다는 그냥 C언어로 모듈을 짜서 붙이는 게 더 빠름\n",
    "- 즉, python에서 CPU를 많이 먹는 부분은 C 모듈을 짜서 붙이거나, 이미 C 모듈로 짜여있는 라이브러리를 사용하거나(Numpy, Scipy 등), 필요하다면 multiprocessing 모듈을 이용하여 멀티코어를 활용\n",
    "    - 그 이상의 CPU-heavy한 작업은 처음부터 C, C++로 짜는 게 맞음\n",
    "    \n",
    "- **쓰레드는 가볍지만 GIL로 인해 계산 처리를 하는 작업은 한번에 하나의 쓰레드에서만 작동. 따라서 cpu 작업이 적고 I/O 작업이 많은 병렬 처리 프로그램에서 효과를 볼 수 있다.......고 하는데,**\n",
    "    - 대규모 연산의 멀티코어의 성능 향상을 보기 위한 것 말고도, I/O가 주가 되는 작업(즉, 여러 개의 I/O 이벤트를 기다리는 것)을 위해서 멀티스레드를 사용하는 경우가 많은데 **이런 경우에도 복잡한 동기화를 해야 하는 멀티쓰레딩을 사용하는 건 낭비**\n",
    "        - 디버깅이 어려움\n",
    "        - 실제로는 I/O를 위해 기다리는 시간이 실제 I/O가 발생했을 때 필요한 처리 작업을 수행하는 시간보다 월등히 긴 경우가 많아 여러 개의 스레드를 관리하기 위한 자원만 낭비하는 꼴이기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GIL(Global Interpreter Lock)\n",
    "* [\"왜 Python에는 GIL이 있는가\" 출처](https://dgkim5360.tistory.com/entry/understanding-the-global-interpreter-lock-of-cpython)\n",
    "- GIL 정의(python wiki): CPython에서의 GIL은 Python 코드(bytecode)를 실행할 때에 여러 thread를 사용할 경우, 단 하나의 thread만이 Python object에 접근할 수 있도록 제한하는 mutex(mutual exclusion) 이다. 그리고 이 lock이 필요한 이유는 CPython이 메모리를 관리하는 방법이 thread-safe하지 않기 때문이다.\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/99111E4A5A7BD82804\" width=\"400\">\n",
    "\n",
    "#### thread-safe ?\n",
    "- 아래 예제에서 print(x)의 결과가 0으로 나오는 게 엇핏 생각하기엔 정상적으로 작동하는 모습이겠지만 실제 계산을 해보면 x의 값은 전혀 이상한 숫자가 됨\n",
    "- 왜 그럴까? 전역 변수 x에 두 개의 thread가 동시에 접근해서 각자의 작업을 하면서 어느 한 쪽의 작업 결과가 반영이 되지 않기 때문\n",
    "    - \"씹혔다\"는 뜻\n",
    "- 이렇게 여러 thread가 공유된 데이터를 변경함으로써 발생하는 문제를 race condition이라고도 함\n",
    "- **따라서 \"thread-safe하다\"는 것은 thread들이 race condition을 발생시키지 않으면서 각자의 일을 수행한다는 뜻**\n",
    "    \n",
    "#### 왜 GIL을 선택해야 했나\n",
    "- Python이 태동하던 시기에는 thread라는 개념이 없었을 당시였고, 쉽고 간결한 언어를 표방했던 Python에 많은 사용자들이 모여들고 있었음\n",
    "- 수많은 C extension들이 이미 만들어졌는데, 시간이 지나서 thread 개념으로 인한 문제를 해결하기 위해서 가장 현실적인 방안은 GIL\n",
    "- 거대한 커뮤니티에서 만들어낸 C extension들을 새로운 메모리 관리 방법에 맞춰서 모두 바꾸는 것은 불가능. 대신 Python이 GIL을 도입하면 C extension들을 바꾸지 않아도 됐던 것\n",
    "- 이렇게 초장기에 만들어진 CPython의 GIL은 현재 Python 3가 되도록 크게 변하지 않은 부분이라고 한다. BDFL은 GIL에 대한 개선을 하고 싶은 사람들에게 이렇게 말했다.\n",
    "> I’d welcome a set of patches into Py3k only if the performance for a single-threaded program (and for a multi-threaded but I/O-bound program) does not decrease.\n",
    ">\n",
    ">단일 thread 프로그램에서의 성능을 저하시키지 않고 GIL의 문제점을 개선할 수 있다면, 나는 그 개선안을 기꺼이 받아들일 것이다.\n",
    "- 그리고 지금까지 그렇게 해서 받아들여진 개선안은 없다고 함\n",
    "\n",
    "#### python에서의 GIL\n",
    "- 단일 thread일 때는 아무런 문제가 없음\n",
    "- CPU가 바쁘게 계산하는 일들은 numpy/scipy에서 GIL 바깥에서 굉장히 효율적인 C 코드로 연산할 수 있음\n",
    "- 병렬 처리에 관해서는 굳이 thread가 아니더라도 multiprocessing이나 asyncio 등의 많은 선택지가 있음\n",
    "- 굳이 thread 간의 동시적인 처리가 필요하다면 다른 Python implementation을 고려해봐도 됨. Jython, IronPython, Stackless Python, PyPy 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520306\n"
     ]
    }
   ],
   "source": [
    "# python에서 thread-safe하지 않은 예제\n",
    "# 숫자가 클수록 thread-safe 하지 않음\n",
    "import threading\n",
    "\n",
    "x = 0  # A shared value\n",
    "\n",
    "def foo():\n",
    "    global x\n",
    "    for i in range(10000000):\n",
    "        x += 1\n",
    "\n",
    "def bar():\n",
    "    global x\n",
    "    for i in range(10000000):\n",
    "        x -= 1\n",
    "\n",
    "t1 = threading.Thread(target=foo)\n",
    "t2 = threading.Thread(target=bar)\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()  # Wait for completion\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi-processing in python\n",
    "\n",
    "- multiprocessing 은 threading 모듈과 유사한 API를 사용하여 프로세스 스포닝(spawning)을 지원하는 패키지\n",
    "    - 프로세스를 스폰(spawn) 한다는 것은 한 프로세스가 자식 프로세스를 새로 만들어 어떤 작업을 위임하는 것을 뜻함. 하지만 자식 프로세스를 만드는 방법이 한가지가 아니고, 때로 spawn 은 그 중 한가지를 가리키는 경우에 사용하기도 함\n",
    "- multiprocessing 패키지는 지역과 원격 동시성을 모두 제공하며 스레드 대신 서브 프로세스를 사용하여 GIL을 효과적으로 회피\n",
    "- 이것 때문에 multiprocessing 모듈은 프로그래머가 주어진 기계에서 다중 프로세서를 최대한 활용할 수 있음\n",
    "- 유닉스와 윈도우에서 모두 실행 가능\n",
    "\n",
    "### 1. very basic multi-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "import sys\n",
    "\n",
    "def worker():\n",
    "    \"\"\"worker function\"\"\"\n",
    "    print('Worker')\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    jobs = []\n",
    "    for i in range(5):\n",
    "        p = multiprocessing.Process(target=worker)\n",
    "        jobs.append(p)\n",
    "        p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker: 1\n",
      "Worker: 2\n",
      "Worker: 0\n",
      "Worker: 3\n",
      "Worker: 4\n"
     ]
    }
   ],
   "source": [
    "# worker id와 함께 출력\n",
    "def worker(num):\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    print('Worker: {}'.format(num))\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    jobs = []\n",
    "    for i in range(5):\n",
    "        p = multiprocessing.Process(target=worker, args=(i,))\n",
    "        jobs.append(p)\n",
    "        p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process-21 Starting\n",
      "my_service Starting\n",
      "worker 1 Starting\n",
      "Process-21 Exiting\n",
      "worker 1 Exiting\n",
      "my_service Exiting\n"
     ]
    }
   ],
   "source": [
    "# 현재 위치와 함께 출력\n",
    "def worker():\n",
    "    name = multiprocessing.current_process().name\n",
    "    print('{} Starting'.format(name))\n",
    "    time.sleep(2)\n",
    "    print('{} Exiting'.format(name))\n",
    "\n",
    "def my_service():\n",
    "    name = multiprocessing.current_process().name\n",
    "    print('{} Starting'.format(name))\n",
    "    time.sleep(3)\n",
    "    print('{} Exiting'.format(name))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    service = multiprocessing.Process(name='my_service', target=my_service)\n",
    "    worker_1 = multiprocessing.Process(name='worker 1', target=worker)\n",
    "    worker_2 = multiprocessing.Process(target=worker) # use default name\n",
    "\n",
    "    worker_1.start()\n",
    "    worker_2.start()\n",
    "    service.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO/Process-6] child process calling self.run()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing some work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO/Process-6] process shutting down\n",
      "[DEBUG/Process-6] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-6] running the remaining \"atexit\" finalizers\n",
      "[INFO/Process-6] process exiting with exitcode 0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "# multi-process 환경에서 로깅\n",
    "def worker():\n",
    "    print('Doing some work', flush=True)\n",
    "    #sys.stdout.flush()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multiprocessing.log_to_stderr(logging.DEBUG)\n",
    "    p = multiprocessing.Process(target=worker)\n",
    "    p.start()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 매핑 함수들 비교\n",
    "\n",
    "- Python3 에서는 map에서 복수의 매개변수를 사용할 수 있도록 한 starmap이 추가\n",
    "- map과 map_async 는 한번에 job의 리스트가 넘겨지지만 apply와 apply_async는 하나의 job만 넘겨짐(loop가 필요)\n",
    "- 하지만 apply_async는 백그라운드에서 job을 병렬로 실행\n",
    "\n",
    "<img src=\"img/Capture.PNG\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 실행되지는 않는 사용법 비교 예시\n",
    "\n",
    "# map\n",
    "results = pool.map(worker, [1, 2, 3])\n",
    "\n",
    "# apply\n",
    "for x, y in [[1, 1], [2, 2]]:\n",
    "    results.append(pool.apply(worker, (x, y)))\n",
    "\n",
    "def collect_result(result):\n",
    "    results.append(result)\n",
    "\n",
    "# map_async\n",
    "pool.map_async(worker, jobs, callback=collect_result)\n",
    "\n",
    "# apply_async\n",
    "for x, y in [[1, 1], [2, 2]]:\n",
    "    pool.apply_async(worker, (x, y), callback=collect_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. pool\n",
    "\n",
    "- Pool 객체는 여러 입력 값에 걸쳐 함수의 실행을 병렬 처리하고 입력 데이터를 프로세스에 분산시키는 편리한 방법을 제공\n",
    "    - 데이터 병렬 처리\n",
    "- 아래 예제는 자식 프로세스가 해당 모듈을 성공적으로 import할 수 있도록 모듈에서 이러한 함수를 정의하는 일반적인 방법을 보여줌\n",
    "    - Pool 를 사용하는 데이터 병렬 처리의 기본 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 20, 40]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    " \n",
    "## 기본적인 예제\n",
    "def doubler(number):\n",
    "    return number * 2\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    numbers = [5, 10, 20]\n",
    "    pool = Pool(processes=3)\n",
    "    print(pool.map(doubler, numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- apply_async 메소드를 사용하여 풀에서 프로세스의 결과를 얻을 수 있음\n",
    "- get 함수를 이용해 process 의 결과를 확인 가능\n",
    "- 호출한 기능에 문제가 생길 경우를 대비해서 타임아웃을 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    " \n",
    "def doubler(number):\n",
    "    return number * 2\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    pool = Pool(processes=3)\n",
    "    result = pool.apply_async(doubler, (25,))\n",
    "    print(result.get(timeout=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 프로세스 간 객체 교환(1) : Queue\n",
    "\n",
    "- multiprocessing 은 두 가지 유형의 프로세스 간 통신 채널을 지원\n",
    "- Queue는 thread-safe, process-safe\n",
    "- multiprocessing 의 Queue임! 그냥 import Queue 는 쓰레드간에 사용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, None, 'hello']\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def f(q):\n",
    "    q.put([42, None, 'hello'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    q = Queue()\n",
    "    p = Process(target=f, args=(q,))\n",
    "    p.start()\n",
    "    print(q.get())    # \"[42, None, 'hello']\" 를 프린트\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 프로세스 간 객체 교환(2) : pipe\n",
    "\n",
    "- 파이프로 연결된 한 쌍의 연결 객체를 돌려주는데 기본적으로 양방향(duplex)\n",
    "- Pipe() 가 반환하는 두 개의 연결 객체는 파이프의 두 끝을 나타냄\n",
    "- 각 연결 객체에는 (다른 것도 있지만) send() 및 recv() 메서드가 있음\n",
    "- 두 프로세스 (또는 스레드)가 파이프의 같은 끝에서 동시에 읽거나 쓰려고 하면 파이프의 데이터가 손상될 수 있음\n",
    "- 물론 파이프의 다른 끝을 동시에 사용하는 프로세스로 인해 손상될 위험은 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, None, 'hello']\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "def f(conn):\n",
    "    conn.send([42, None, 'hello'])\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parent_conn, child_conn = Pipe()\n",
    "    p = Process(target=f, args=(child_conn,))\n",
    "    p.start()\n",
    "    print(parent_conn.recv())   # \"[42, None, 'hello']\" 를 프린트\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 성능 비교 ?????????\n",
    "- 듀얼코어 환경\n",
    "- [제대로 된 결과 참고](https://doorbw.tistory.com/205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # # SINGLE PROCESSING # # \n",
      "1 : 2500000\n",
      "1 : 5000000\n",
      "1 : 7500000\n",
      "1 : 10000000\n",
      "2 : 2500000\n",
      "2 : 5000000\n",
      "2 : 7500000\n",
      "2 : 10000000\n",
      "3 : 2500000\n",
      "3 : 5000000\n",
      "3 : 7500000\n",
      "3 : 10000000\n",
      "4 : 2500000\n",
      "4 : 5000000\n",
      "4 : 7500000\n",
      "4 : 10000000\n",
      "SINGLE PROCESSING TIME : 5.079680442810059\n",
      "\n",
      " # # MULTI PROCESSING # # \n",
      "3 : 2500000\n",
      "1 : 2500000\n",
      "4 : 2500000\n",
      "2 : 2500000\n",
      "4 : 5000000\n",
      "1 : 5000000\n",
      "3 : 5000000\n",
      "2 : 5000000\n",
      "4 : 7500000\n",
      "1 : 7500000\n",
      "3 : 7500000\n",
      "2 : 7500000\n",
      "4 : 10000000\n",
      "1 : 10000000\n",
      "3 : 10000000\n",
      "2 : 10000000\n",
      "MULTI PROCESSING TIME : 5.637576580047607\n",
      "\n",
      " # # MULTI THREADING # # \n",
      "1 : 2500000\n",
      "1 : 5000000\n",
      "1 : 7500000\n",
      "1 : 10000000\n",
      "2 : 2500000\n",
      "2 : 5000000\n",
      "2 : 7500000\n",
      "2 : 10000000\n",
      "3 : 2500000\n",
      "3 : 5000000\n",
      "3 : 7500000\n",
      "3 : 10000000\n",
      "4 : 2500000\n",
      "4 : 5000000\n",
      "4 : 7500000\n",
      "4 : 10000000\n",
      "MULTI THREADING TIME : 5.264259576797485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from functools import partial \n",
    "from threading import Thread\n",
    "import multiprocessing\n",
    "import time\n",
    " \n",
    "def singleCount(cnt,name):\n",
    "    for i in range(1,10000001):\n",
    "        cnt += 1\n",
    "        if(i%5000000 == 0):\n",
    "            print(name,\":\",i)\n",
    " \n",
    "lists = ['1','2','3','4']\n",
    "# single process start\n",
    "cnt = 0\n",
    "print(\" # # SINGLE PROCESSING # # \")\n",
    "start_time = time.time()\n",
    "for each in lists:\n",
    "    singleCount(cnt,each)\n",
    "print(\"SINGLE PROCESSING TIME : %s\\n\" %(time.time()-start_time))\n",
    " \n",
    "# multi process start\n",
    "cnt = 0\n",
    "print(\" # # MULTI PROCESSING # # \")\n",
    "start_time = time.time()\n",
    "pool = multiprocessing.Pool(processes=4)\n",
    "func = partial(singleCount, cnt)\n",
    "pool.map(func, lists)\n",
    "pool.close()\n",
    "pool.join()\n",
    "print(\"MULTI PROCESSING TIME : %s\\n\" %(time.time()-start_time))\n",
    " \n",
    "#multi threading start\n",
    "cnt = 0\n",
    "print(\" # # MULTI THREADING # # \")\n",
    "start_time = time.time()\n",
    "th1 = Thread(target=singleCount, args=(cnt,\"1\"))\n",
    "th1.start()\n",
    "th1.join()\n",
    "th2 = Thread(target=singleCount, args=(cnt,\"2\"))\n",
    "th2.start()\n",
    "th2.join()\n",
    "th3 = Thread(target=singleCount, args=(cnt,\"3\"))\n",
    "th3.start()\n",
    "th3.join()\n",
    "th4 = Thread(target=singleCount, args=(cnt,\"4\"))\n",
    "th4.start()\n",
    "th4.join()\n",
    "print(\"MULTI THREADING TIME : %s\\n\" %(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. PicklingError\n",
    "- [stack overflow 글 참고: python-multiprocessing-picklingerror-cant-pickle-type-function](https://stackoverflow.com/questions/8804830/python-multiprocessing-picklingerror-cant-pickle-type-function)\n",
    "\n",
    "- 멀티프로세싱 과정에서 아래와 같은 `PicklingError` 발생\n",
    "    - 사용하는 함수가 최상위 위치에서 정의되지 않는 경우: class 내부에 정의된 함수를 사용할 수가 없음\n",
    "    - 사용하는 함수가 pool 이후에 선언된 경우\n",
    "        - `_pickle.PicklingError: Can't pickle <function count at 0x7f62ebfb69d8>: attribute lookup count on __main__ failed`\n",
    "\n",
    "    - async job에 입력한 객체가 inbuilt function을 하나라도 가지고 있을 경우\n",
    "        - `_pickle.PicklingError: Can't pickle <type 'function'>: attribute lookup __builtin__.function failed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "class Foo():\n",
    "    @staticmethod\n",
    "    def work(self):\n",
    "        pass\n",
    "\n",
    "pool = mp.Pool()\n",
    "foo = Foo()\n",
    "pool.apply_async(foo.work)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 자료로 업로드한 `multiprocessing.py`를 line_profiler로 실행하면 아래와 같은 에러가 발생\n",
    "``` bash\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/lynn/.virtualenvs/data/bin/kernprof\", line 11, in <module>\n",
    "    sys.exit(main())\n",
    "  File \"/home/lynn/.virtualenvs/data/lib/python3.5/site-packages/kernprof.py\", line 222, in main\n",
    "    execfile(script_file, ns, ns)\n",
    "  File \"/home/lynn/.virtualenvs/data/lib/python3.5/site-packages/kernprof.py\", line 35, in execfile\n",
    "    exec_(compile(f.read(), filename, 'exec'), globals, locals)\n",
    "  File \"multiprocessing.py\", line 46, in <module>\n",
    "    multi_process(lists)\n",
    "  File \"/home/lynn/.virtualenvs/data/lib/python3.5/site-packages/line_profiler.py\", line 115, in wrapper\n",
    "    result = func(*args, **kwds)\n",
    "  File \"multiprocessing.py\", line 23, in multi_process\n",
    "    pool.map(func, lists)\n",
    "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 260, in map\n",
    "    return self._map_async(func, iterable, mapstar, chunksize).get()\n",
    "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 608, in get\n",
    "    raise self._value\n",
    "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 385, in _handle_tasks\n",
    "    put(task)\n",
    "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 206, in send\n",
    "    self._send_bytes(ForkingPickler.dumps(obj))\n",
    "  File \"/usr/lib/python3.5/multiprocessing/reduction.py\", line 50, in dumps\n",
    "    cls(buf, protocol).dump(obj)\n",
    "_pickle.PicklingError: Can't pickle <function singleCount at 0x7f9595cbf9d8>: attribute lookup singleCount on __main__ failed\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대안으로 `pathos.multiprocessing` 사용: [참고](https://stackoverflow.com/questions/26059764/python-multiprocessing-with-pathos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- https://magi82.github.io/process-thread/\n",
    "- https://python.flowdas.com/library/multiprocessing.html\n",
    "- http://blog.naver.com/PostView.nhn?blogId=parkjy76&logNo=221089918474\n",
    "- https://hamait.tistory.com/755\n",
    "- https://doorbw.tistory.com/205"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
